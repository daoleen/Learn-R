####                            Тесты Стьюдента                                         ####
# Наиболее обычная деятельность исследователей – это сравнение двух групп объектов. Правда ли, что
# больные, получившие новое лекарство, чувствуют себя лучше пациентов, которых лечат старым
# способом? Правда ли, что одна технология производства характеризуется меньшим процентом брака,
# чем другая? Какой из методов преподавания более эффективен по соотношению цены и качества?
# Если результат выражен в виде категориальной переменной, можно использовать методы, которые
# были описаны в разделе 7.3. Здесь мы сосредоточимся на сравнении групп, где исследуется
# непрерывная переменная, значения которой распределены нормально.
# В качестве примера мы используем набор данных UScrime, входящий в пакет MASS. Эти
# данные содержат информацию о влиянии карательного законодательства на уровень преступности в
# 47 штатах США в 1960 году. Мы будем исследовать переменные Prob (вероятность угодить в
# тюрьму), U1 (уровень безработицы для городских жителей мужского пола в возрасте от 14 до 24 лет)
# и U2 (этот же показатель для мужчин в возрасте 35–39 лет). Категориальная переменная So
# (указывающая, относится ли штат к группе южных штатов) будет использована в качестве
# группирующей. Данные были масштабированы авторами исследования. Примечание: я раздумывал,
# не назвать ли этот раздел «Преступление и наказание на Далеком Юге», но благоразумие взяло верх.

# Тест Стьюдента для независимых переменных
# Правда ли, что вероятность оказаться в тюрьме после совершения преступления выше в южных
# штатах? Чтобы ответить на этот вопрос, нужно сравнить вероятность лишения свободы в южных
# штатах и остальных. Для проверки гипотезы о равенстве двух средних значений можно использовать
# тест Стьюдента для независимых переменных. В этом случае подразумевается, что эти две группы не
# зависят друг от друга и данные происходят из нормальных распределений. Функцию можно
# применять в двух форматах. Или в таком:
#  t.test(y ~ x, data)
# где y – это числовая переменная, а x – дихотомическая, или в таком:
#  t.test(y1, y2)
# где y1 и y2 – это числовые векторы (исследуемые переменные для каждой из групп).
# Необязательный аргумент data назначает матрицу или таблицу данных, в которой содержатся
# переменные. В отличие от большинства статистических программ, в R по умолчанию не
# подразумевается равенство дисперсий и используется трансформация степеней свободы Велша
# (Welsh degrees of freedom modification). Указать на равенство дисперсий можно при помощи
# параметра var.equal=TRUE. По умолчанию используется двусторонняя альтернативная гипотеза
# (о том, что средние значения различаются, но неважно, как). Можно использовать опции
# alternative="less" или alternative="greater", чтобы проверить наличие различий в
# определенном направлении.
# При помощи приведенного программного кода вы сравниваете вероятность попасть в тюрьму
# в южных (группа 1) и остальных (группа 0) штатах при помощи двустороннего теста, не предполагая
# равенство дисперсий.
library(MASS)
t.test(Prob ~ So, data=UScrime)
# На основании этого теста можно отвергнуть гипотезу о равенстве шансов попасть в тюрьму в южных
# и остальных штатах (p<0.001).
# Примечание. Поскольку исследуемая переменная выражена в долях единицы, перед выполнением
# теста Стьюдента можно попробовать привести ее к нормальному распределению. В данном
# случае все разумные преобразования этой переменной (Y/1-Y, log(Y/1-Y), arcsin(Y),
# arcsin(sqrt(Y)) приведут к одному и тому же результату. Преобразования переменных
# подробно обсуждаются в главе 8.


####                            Тест Стьюдента для зависимых переменных                         ####
# В качестве второго примера, можно узнать, правда ли уровень безработицы у юношей (14–24 года)
# выше, чем у мужчин (35–39 лет). В данном случае эти две группы не независимы. Вы ведь не станете
# ожидать, что уровень безработицы у юношей и у мужчин в Алабаме – независимые величины? Когда
# данные для двух групп связаны между собой, следует проводить тест для зависимых переменных.
# Это же относится и к результатам повторных измерений или к измерениям одного и того же объекта,
# проведенным до и после какого-либо воздействия.
# Подразумевается, что разность значений параметра для двух групп имеет нормальное
# распределение. В данном случае формат применения функции таков:
#   t.test(y1, y2, paired=TRUE)
# где y1 и y2 – это числовые векторы для двух зависимых групп. Результаты применения теста
# выглядят следующим образом:
library(MASS)
sapply(UScrime[c("U1","U2")], function(x)(c(mean=mean(x),sd=sd(x))))
with(UScrime, t.test(U1, U2, paired=TRUE))
# Разность средних (61.5) достаточно велика, чтобы обосновать отклонение гипотезы о равенстве
# уровня безработицы для юношей и мужчин (у юношей она выше). В самом деле, вероятность
# получить такое значение разности средних для выборки в то время, как они будут равны для
# генеральной совокупности, меньше 0.00000000000000022 (то есть, 2.2e–16).

# Когда существует больше двух групп
# Что вы будете делать, если вам понадобится одновременно сравнить больше двух групп? Если
# предположить, что эти группы независимо происходят из нормального распределения, то можно
# использовать дисперсионный анализ (ANOVA). Это сложный подход, который можно применять для
# анализа разных типов экспериментов и квази-экспериментов, поэтому он заслуживает отдельной
# главы. Вы можете спокойно прервать чтение этого раздела в любом месте на и перейти к главе 9.


####                        Непараметрические тесты межгрупповых различий                         ####
# Если у вас есть непараметрические данные, можно обратиться к непараметрическим методам.
# Описанные в этом разделе методы можно использовать, например, в том случае, если исследуемые
# переменные порядковые, или их распределение сильно отличается от нормального.

# Сравнение двух групп
# Если две группы независимы, можно использовать тест ранговых сумм Вилкоксона (Wilcoxon rank
# sum test), более широко известный как тест Манна-Уитни (Mann–Whitney U test), чтобы узнать,
# происходят ли наблюдения из одного и того же распределения вероятностей (иными словами, правда
# ли вероятность получить более высокие значения выше в одной выборке, чем в другой). Эту
# функцию можно применять в таком формате:
#   wilcox.test(y ~ x, data)
# где y – это числовая переменная, а x – дихотомическая, или в таком:
#   wilcox.test(y1, y2)
# где y1 и y2 – это исследуемые переменные для каждой группы. Необязательный аргумент data
# назначает матрицу или таблицу данных, в которой содержатся исследуемые переменные. По
# умолчанию это двухсторонний тест. Можно добавить параметр exact, чтобы вычислить точный
# критерий (exact test) и параметр alternative="less" или alternative="greater", чтобы
# проверить соответствующую одностороннюю гипотезу.
# Если применить тест Вилкоксона 9 для решения вопроса о вероятности попадания в тюрьму,
# обсуждаемого в предыдущем разделе, вы получите следующий результат:
with(UScrime, by(Prob, So, median))
wilcox.test(Prob ~ So, data=UScrime)
# Вновь можно отвегнуть гипотезу о равенстве вероятностей оказаться в тюрьме в южных и прочих
# штатах (p<0.01).
# Тест Вилкоксона – это непараметрическая альтернатива тесту Стьюдента для зависимых
# переменных. Его следует применять в тех случаях, когда группы зависимы друг от друга и не
# наблюдается нормальное распределение значений. Формат применения функции такой же, как и в
# предыдущем примере, только нужно добавить параметр paired=TRUE. Давайте применим этот тест
# для решения вопроса о безработице из предыдущего раздела.
sapply(UScrime[c("U1","U2")], median)
with(UScrime, wilcox.test(U1, U2, paired=TRUE))
# Вы вновь пришли к тому же выводу, что и в случае теста Стьюдента для зависимых переменных.
# В данном случае, параметрические тесты Стьюдента и их непараметрические аналоги дали
# одинаковые результаты. В том случае, если условия применения тестов Стьюдента выполняются,
# параметрические тесты имеют большую мощность (вероятность обнаружить существующие
# различия выше) по сравнению с непараметрическими. Непараметрические тесты разумно применять,
# когда условия применения параметрических тестов сильно нарушаются (например, для порядковых
# переменных).


# Сравнение более чем двух групп
# Когда нужно сравнить больше двух групп, приходится использовать другие методы. Рассмотрим
# набор данных state.x77 из раздела 7.4. В нем содержатся данные о численности населения,
# доходе, уровне неграмотности, среднем продолжительности жизни, уровне преступности и доле
# людей со средним образовании в разных штатах Америки. Что, если вы хотите сравнить уровень
# неграмотности в четырех регионах страны (Северо-Восток – Northeast, Юг – South, Север – North
# Central и Запад – West)? Это называется односторонний дизайн эксперимента, для решения
# поставленного вопроса существуют и параметрические, и непараметрические методы.
# Если наши данные не удовлетворяют требованиям ANOVA для оценки межгрупповых
# различий средних значений, можно использовать непараметрические методы. Если группы
# независимы, лучше всего подойдет тест Краскела-Уоллиса (Kruskal–
# Wallis test). Если группы зависимы (например, это результаты повторных измерений или данные
# эксперимента с блочным дизайном), то нужно использовать тест Фридмана (Friedman test).
# Формат применения теста Краскела-Уоллиса таков:
#   kruskal.test(y ~ A, data)
# где y – это числовая переменная отклика, A – группирующая переменная, принимающая два
# значения и более (в случае с двумя значениями этот тест идентичен тесту Вилкоксона). Формат
# применения тест Фридмана следующий:
#   friedman.test(y ~ A | B, data)
# где y – это числовая переменная отклика, A – группирующая переменная, B – блокирующая
# переменная, в которой содержится информация о парных наблюдениях. В обоих случаях data – это
# необязательный аргумент, который назначает матрицу или таблицу данных, где содержатся
# исследуемые переменные.
# Давайте используем тест Краскела-Уоллиса для решения вопроса об уровне неграмотности.
# Сначала нужно добавить в наш набор данных информацию о региональной принадлежности штатов.
# Эта информация содержится в наборе данных state.region, входящем в базовую версию
# программы.
states <- as.data.frame(cbind(state.region, state.x77))
kruskal.test(Illiteracy ~ state.region, data=states)
# Его результаты свидетельствуют о том, что уровень неграмотности не одинаков во всех четырех
# регионах (p<0.001).
# Хотя мы опровергли нулевую гипотезу об отсутствии различий, из результатов теста не ясно,
# какие регионы достоверно отличаются от других. Чтобы ответить на этот вопрос, можно сравнить
# попарно все группы при помощи теста Вилкоксона. Более изящное решение проблемы состоит в
# одновременном множественном сравнении всех пар регионов с контролем значений статистической
# ошибки первого рода (вероятность найти несуществующие различия). Этот подход реализован в
# пакете npmc.
# Честно говоря, здесь я немного вышел за пределы основных методов, заявленных в названии
# этой главы, но поскольку рассматрение этого подхода вполне здесь уместено, я надеюсь, что вы меня
# простите. Для начала убедитесь, что пакет npmc установлен. Для выполнения одноименной команды
# нужно, чтобы ваши данные были представлены в виде двух столбцов, один из которых назван var
# (зависимая переменная), а другой – class (группирующая переменная). Приведенный ниже
# программный код содержит пример использования этой команды.
# Программный код 7.20. Непараметрические множественные сравнения
class <- state.region
var <- state.x77[,c("Illiteracy")]
mydata <- as.data.frame(cbind(class, var))
rm(class, var)
library(npmc)
summary(npmc(mydata), type="BF")
aggregate(mydata, by=list(mydata$class), median)
# Команда npmc() осуществляет шесть попарных сравнений (Северо-Восток с Югом, Северо-Восток
# с Севером, Северо-Восток с Западом, Юг с Севером, Юг с Западом и Север с Западом) . Из
# результатов двустороннего теста на достоверность (p.value.2s) можно видеть, что Юг достоверно
# отличается от трех других регионов, а они между собой не различаются. Видно , что для Юга в
# среднем характерны более высокие значения уровня неграмотности. Учтите, что при этом подходе
# для промежуточных вычислений используются случайные значения, так что результаты будут слегка
# варьировать раз от раза.



####                            Визуализация групповых различий                               ####
# В разделах 7.4 и 7.5 мы рассматривали статистические методы сравнения групп. Визуальный анализ
# межгрупповых различий – это тоже очень важный этап комплексного подхода к анализу данных. Онпозволяет получить информацию о величине различий, выявить особенности распределения
# значений (ассиметрию, бимодальность, выбросы), которые влияют на результаты сравнения, и
# оценить, насколько данные удовлетворяют требованиям тестов. В R реализовано множество
# графических методов для сравнения групп, включая ящики с усами (простые, выемчатые и
# cкрипичные), которые описаны в разделе 6.5; наложенные друг на друга диаграммы плотности ядра,
# рассмотренные в разделе 6.4.1; и графические методы оценки соответствия данных требованиям
# тестов, которые обсуждаются в главе 9.