####                                Корреляции                                            ####
# Коэффициенты корреляции используются для описания связей между количественными
# переменными. Знак коэффициента (+ или –) свидетельствует о направлении связи (положительная
# отрицательная), а величина коэффициента показывает силу связи (варьирует от 0 – нет связи, до
# 1 – абсолютно предсказуемая взаимосвязь).
# В этом разделе мы рассмотрим разные коэффициенты корреляции наряду с тестами на
# достоверность. Мы будем использовать набор данных state.x77, входящий в базовую версию R.
# В нем содержаться данные о численности, доходе, проценте неграмотного населения, средней
# продолжительности жизни, уровне преступности и доле людей со средним образованием для 50
# штатов США в 1977 году. Там также есть данные о температурном режиме и о площади штатов, но
# мы опустим их, чтобы сэкономить место. Наберите help(state.x77), чтобы узнать больше об
# этих данных. В дополнение к базовой версии программы нам понадобятся пакеты psych и ggm.

####                            Типы корреляций                                           ####
# В R можно рассчитывать разные коэффициенты корреляции, включая коэффициенты Пирсона,
# Спирмена, Кэнделла, частные, полихорические и многорядные. Давайте рассмотрим их по порядку.

# Коэффициенты Пирсона, Спирмена и Кэнделла
# Коээфициент корреляции Пирсона по смешанным моментам (Pearson product moment correlation)
# отражает степень линейной связи между двумя количественными переменными. Коэффициент
# ранговой корреляции Спирмана (Spearman’s Rank Order correlation) – мера связи между двумя
# ранжированными переменными. Тау Кэнделла (Kendall’s Tau) – также непараметрический
# показатель ранговой корреляции.
# Функция cor() позволяет вычислить все три коэффициента, а функция cov() рассчитывает
# ковариации. У этих функций есть много опций, но упрощенный формат вычисления корреляций
# таков:
#  cor(x, use= , method= )

# Таблица 7.3. Опции функций cor() и cov()
# Опция                |Описание                
#---------------------------------------------------------------------------------------
# x                    |Матрица или таблица данных
#-----------------------
# use=                 |Упрощает работу с пропущенными данными. Может принимать следующие
#                      |значения: all.obs (предполагается, что пропущенные значения отсутствуют, их
#                      |наличие вызовет сообщение об ошибке), everything (любая корреляция,
#                      |включающая строку с пропущенным значением, не будет вычисляться –
#                      |обозначается как missing), complete.obs (учитываются только
#                      |cтроки без пропущенных значений) и pairwise.complete.obs (учитываются
#                      |все полные наблюдения для каждой пары переменных в отдельности)
#-----------------------
# method=              |Определяет тип коэффициента корреляции. Возможные значения – pearson,
#                      |spearman или kendall.
#----------------------------------------------------------------------------------------

# Значения опций по умолчанию: use="everything" и method="pearson". Пример представлен
# в приведенном ниже программном коде.
# Программный код 7.17. Ковариации и корреляции
states<- state.x77[,1:6]
cov(states)
cor(states)
cor(states, method="spearman")
# Первая команда выводит на экран таблицу дисперсий и ковариаций. Вторая – таблицу
# корреляционных коэффициентов Пирсона, а третья – корреляционных коэффициентов Спирмена.
# Можно увидеть, например, что между средним доходом и долей людей со средним образованием
# существует сильная положительная корреляция, а между средней продолжительностью жизни и
# долей неграмотного населения – сильная отрицательная корреляция.Обратите внимание на то, что по умолчанию получается квадратная таблица (приведены
# сочетания всех переменных со всеми). Вы также можете вывести на экран прямоугольную таблицу,
# как в приведенном примере.
x <- states[,c("Population", "Income", "Illiteracy", "HS Grad")]
y <- states[,c("Life Exp", "Murder")]
cor(x,y)
# Этот способ применения функции особенно удобен, когда вы интересуетесь связью между двумя
# наборами переменных. Учтите, что эти результаты не позволяют узнать, отличаются ли достоверно
# коэффициенты корреляции от нуля (иными словами, можно ли на основании имеющейся выборки
# уверенно утверждать, что коэффициент корреляции для генеральной совокупности отличается от
# нуля). Для этого нужно применять тесты на достоверность (описаны в разделе 7.3.2).

# Частные корреляции
# Частная корреляция – это корреляция между двумя количественными переменными, зависящими в
# свою очередь от одной или более других количественных переменных. Для вычисления
# коэффициентов частной корреляции можно использовать функцию pcor() из пакета ggm. Этот
# пакет не поставляется с базовой версией программы, так что не забудьте установить его перед
# первым использованием. Формат применения этой функции таков:
#   pcor(u, S)
# где u – это числовой вектор, в котором первые два числа – это номера переменных, для которых
# нужно вычислить коэффициент, а остальные числа – номера «влияющих» переменных (воздействие
# которых должно быть отделено). S – это ковариационная матрица для всех этих переменных.
# Проиллюстрируем это на примере.
library(ggm)
# частная корреляция между численностью населения и уровнем преступности,
# освобожденная от влияния дохода, доли неграмотного населения и долей
# людей со средним образованием
pcor(c(1,5,2,3,6), cov(states))
# В данном случае 0.346 – это коэффициент корреляции между численностью населения и уровнем
# преступности без влияния дохода, доли неграмотного населения и долей людей со средним
# образованием. Частные корреляции обычно используются в социологии.

# Другие типы корреляций
# Функция hetcor() из пакета polycor позволяет вычислять комбинированную корреляционную
# матрицу, содержащую коэффициенты корреляции Пирсона для числовых переменных, многорядные
# корреляции между числовыми и порядковыми переменными, полихорические корреляции между
# порядковыми переменными и тетрахорические корреляции между двумя дихотомическими
# переменными. Многорядные, полихорические и тетрахорические корреляции могут быть вычислены
# для порядковых и дихотомических переменных, которые происходят из нормального распределения.
# Дополнительную информацию об этих типах корреляций можно получить из справочного материала
# для данного пакета.



####                        Проверка корреляций на достоверность                        ####
# Как проверить на достоверность вычисленные коэффициенты корреляции? Стандартная нулевая
# гипотеза – это отсутствие связи (то есть коэффициент корреляции для генеральной совокупности
# равен нулю). Для проверки достоверности отдельных корреляционных коэффициентов Пирсона,
# Спирмена и Кэнделла можно использовать функцию cor.test(). Упрощенный формат ее
# применения таков:
#  cor.test(x, y, alternative = , method = )
# где x и y – это переменные, корреляция между которыми исследуется, опция alternative
# определяет тип теста ("two.side", "less" или "greater"), опция method задает тип
# корреляции ("pearson", "kendall" или "spearman"). Используйте опцию
# alternative="less" для проверки гипотезы о том, что в генеральной совокупности
# коэффициент корреляции меньше нуля, а опцию alternative="greater" – для проверки того,
# что он больше нуля. По умолчанию alternative="two.side" (проверяется гипотеза о том, что
# коэффициент корреляции в генеральной совокупности не равен нулю). Пример приведен в
# следующем программном коде.
# Программный код 7.18. Проверка достоверности коэффициента корреляции
cor.test(states[,3], states[,5])
# Здесь нулевая гипотеза заключается в том, что пирсоновский коэффициент корреляции между
# средней продолжительностью жизни и уровнем преступности равен нулю. Если этот коэффициент
# для генеральной совокупности равен нулю, то его значение для случайной выборки будет равно
# 0.703 реже, чем в одном случае из 10 миллионов (это и означает p-value = 1.258e-08). Учитывая,
# насколько мала вероятность, мы отвергнем нулевую гипотезу и примем рабочую – о том, что
# значение этого коэффициента для генеральной совокупности не равно нулю.
# К сожалению, при помощи функции cor.test() одновременно можно проверить
# достоверность только одного коэффициента корреляции. Зато в пакете psych есть функция
# corr.test(), которая позволяет сделать больше. С ее помощью можно вычислить коэффициенты
# корреляции Пирсона, Спирмена и Кэнделла между несколькими переменными и оценить их
# достоверность. Пример приведен в следующем программном коде.
# Программный код 7.19. Создание матрицы коэффициентов корреляции и проверка их достоверности
# при помощи функции corr.test()
library(psych)
corr.test(states, use="complete")
# Опция use= может принимать значения "pairwise" или "complete" (для попарного или
# построчного удаления пропущенных значений соответственно). Значения опции method= бывают
# следующими: "pearson" (по умолчанию), "spearman" или "kendall". Из приведенного
# примера видно, что коэффициент корреляции между численностью населения и долей людей со
# средним образованием (–0.10) не отличается достоверно от нуля (p=0.5).

# Другие тесты на достоверность
# В разделе 7.4.1 мы обсуждали частные корреляции. Отсутствие зависимости между двумя
# переменными, без учета влияния нескольких других переменных можно проверить при помощи
# функции pcor.test() из пакета psych при условии, что значения всех этих переменных
# распределены нормально. Формат применения этой функции таков:
#   pcor.test(r, q, n)
# где r – это частная корреляция, вычисленная при помощи функции pcor(), q – число переменных,
# влияние которых исключается, n – объем выборки.
# Прежде чем закончить обсуждение этой темы, нужно упомянуть о функции r.test() из
# пакета psych, которая позволяет проводить ряд полезных тестов на достоверность. Эту функцию
# можно использовать, чтобы проверять достоверность:
# - коэффициента корреляции;
# - различий между двумя независимыми корреляциями;
# - различий между двумя зависимыми корреляциями, у которых есть одна общая переменная;
# - различий между двумя зависимыми корреляциями между разными парами переменных.
# Введите help(r.test), чтобы получить более полную информацию.


####                            Визуализация корреляций                               ####
# Связи между парами переменных можно визуализировать при помощи диаграмм рассеяния и
# составленных из них матриц. Коррелограммы – это непревзойденный действенный метод сравнения
# большого числа коэффициентов корреляции в легко интерпретируемой форме. Все эти графические
# подходы рассмотрены в главе 11.